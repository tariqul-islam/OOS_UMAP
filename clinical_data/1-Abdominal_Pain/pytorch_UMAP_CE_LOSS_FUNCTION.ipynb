{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from scipy import optimize\n",
    "\n",
    "from scipy.io import savemat\n",
    "\n",
    "\n",
    "with open('YALE_ABDOMINAL_PAIN.npy', 'rb') as f:\n",
    "    X_train = np.load(f)\n",
    "    y_train = np.load(f).reshape(-1)\n",
    "    X_test = np.load(f)\n",
    "    y_test = np.load(f).reshape(-1)\n",
    "\n",
    "classes = ['0', '1']\n",
    "\n",
    "n = X_train.shape[0]\n",
    "    \n",
    "print(X_train.shape, y_train.shape, X_train.dtype)\n",
    "print(X_test.shape, y_test.shape, X_test.dtype)\n",
    "    \n",
    "%matplotlib notebook\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "\n",
    "ump = umap.UMAP(n_neighbors=30,\n",
    "        min_dist=0.1,\n",
    "        n_components=2,\n",
    "        random_state=150,\n",
    "        metric= 'euclidean')\n",
    "\n",
    "y_umap = ump.fit_transform(X_train)\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(y_umap[:,0], y_umap[:,1], c=y_train, s=0.1, cmap='Spectral')\n",
    "\n",
    "cbar = plt.colorbar(boundaries=np.arange(11)-0.5)\n",
    "cbar.set_ticks(np.arange(10))\n",
    "cbar.set_ticklabels(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(y_umap[:,0], y_umap[:,1], c=y_train, s=0.1, cmap='Spectral')\n",
    "\n",
    "cbar = plt.colorbar(boundaries=np.arange(len(classes)+1)-0.5)\n",
    "cbar.set_ticks(np.arange(len(classes)))\n",
    "cbar.set_ticklabels(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = euclidean_distances(X_train, squared = False)\n",
    "\n",
    "#with open('mnist_distances.npy', 'rb') as f:\n",
    "#    dist = np.load(f)\n",
    "\n",
    "\n",
    "#print(dist[0:4, 0:4])\n",
    "print('\\n')\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dist[0:4, 0:4])\n",
    "print( np.sum((X_train[1,:] - (X_train[6,:]+X_train[5,:]))**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors=30\n",
    "\n",
    "sort_idx = np.argsort(dist,axis=1)\n",
    "\n",
    "sort_idx = sort_idx[:,1:n_neighbors+1]\n",
    "print(sort_idx.shape, sort_idx[:,1].shape)\n",
    "\n",
    "\n",
    "rho = [ dist[i, sort_idx[i,0] ] for i in range(n)]\n",
    "rho = np.array(rho)\n",
    "\n",
    "print(rho[0:4])\n",
    "print(rho.shape, rho.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(dist[0,[0,1,5,6]])\n",
    "#print(dist[0,0:7])\n",
    "\n",
    "import gc\n",
    "\n",
    "print(gc.collect())\n",
    "\n",
    "#with open('rho_mnist.npy', 'wb') as f:\n",
    "#    np.save(f, rho)\n",
    "    \n",
    "#print(rho.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def prob_high_dim(sigma, dist_row):\n",
    "    \"\"\"\n",
    "    For each row of Euclidean distance matrix (dist_row) compute\n",
    "    probability in high dimension (1D array)\n",
    "    \"\"\"\n",
    "    d = dist[dist_row] - rho[dist_row];\n",
    "    d[ d < 0 ] = 0\n",
    "    return np.exp(-d / sigma)\n",
    "\n",
    "def k(prob):\n",
    "    \"\"\"\n",
    "    Computer n_neighbor = k (scalar) for each 1D array of high-dimensional probability\n",
    "    \"\"\"\n",
    "    return np.power(2, np.sum(prob))\n",
    "'''\n",
    "temp = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight_function(dists, rho, sigma):\n",
    "    d = dists - rho\n",
    "    #print(d)\n",
    "    d[d<0] = 0\n",
    "    weight = np.exp(- d / sigma )\n",
    "    return weight\n",
    "\n",
    "\n",
    "def search_sigma(dists, rho, k, tol = 10**-5, n_iteration=200):\n",
    "    sigma_min = 0\n",
    "    sigma_max = 1000\n",
    "    \n",
    "    cur_sigma = 100\n",
    "    \n",
    "    logk = np.log2(k)\n",
    "    #print(logk)\n",
    "    \n",
    "    for i in range(n_iteration):\n",
    "        \n",
    "        cur_sigma = (sigma_min+sigma_max)/2\n",
    "        probs = get_weight_function(dists,rho,cur_sigma)\n",
    "        weight = np.sum(probs)\n",
    "        #print(weight)\n",
    "        \n",
    "        if np.abs(logk - weight) < tol:\n",
    "            break\n",
    "        \n",
    "        if weight < logk:\n",
    "            sigma_min = cur_sigma\n",
    "        else:\n",
    "            sigma_max = cur_sigma\n",
    "        \n",
    "    return cur_sigma, probs\n",
    "\n",
    "#sigma, weights = search_sigma(dists = dist[0,sort_idx[0,:]],rho = rho[0],k = n_neighbors)\n",
    "\n",
    "#print(np.sum(np.exp( -(dist[0,1:] - rho[0]) / sigma ) ))\n",
    "\n",
    "#print(dist[0,:] - rho[0], dist[0,0], rho[0])\n",
    "\n",
    "#print(sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmas = []\n",
    "\n",
    "directed_graph = []\n",
    "#'''\n",
    "for i in range(n):\n",
    "    if (i+1)%10000 == 0:\n",
    "        print('Processed ', i+1, ' of ', n, ' samples.')\n",
    "    sigma, weights = search_sigma(dists = dist[i,sort_idx[i,:]],rho = rho[i],k = n_neighbors)\n",
    "    \n",
    "    probs = np.zeros(n)\n",
    "    probs[sort_idx[i,:]] = weights\n",
    "    #print(sum(weights), np.log2(n_neighbors))\n",
    "    #print(sort_idx[i,:])\n",
    "    #print(probs[1770:1780])\n",
    "    \n",
    "    directed_graph.append(probs)\n",
    "\n",
    "prob = np.array(directed_graph)\n",
    "#'''  \n",
    "\n",
    "#with open('probs_n_neighbor30.npy', 'rb') as f:\n",
    "#    prob = np.load(f)\n",
    "    \n",
    "\n",
    "#print(prob.shape)\n",
    "\n",
    "\n",
    "#print(prob[0:10,0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "#'''\n",
    "import numba \n",
    "from numba import prange\n",
    "@numba.jit(nopython=True, parallel=True)\n",
    "def symmetrization_step(prob):\n",
    "    P = np.zeros((n,n),dtype=np.float32)\n",
    "\n",
    "    for i in prange(n):\n",
    "        #if i%1000 == 0:\n",
    "        #    print('Completed ', i, ' of ', n)\n",
    "        for j in prange(i,n):\n",
    "            p = prob[i,j] + prob[j,i] - prob[i,j] * prob[j,i]\n",
    "            P[i,j] = p\n",
    "            P[j,i] = p\n",
    "            \n",
    "    return P\n",
    "\n",
    "\n",
    "P = symmetrization_step(prob)\n",
    "#'''\n",
    "print(np.sum(P[0,:]==0))\n",
    "\n",
    "    \n",
    "\n",
    "print(P.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(P[0,P[0,:]>0])\n",
    "np.sum(P[0,P[0,:]>0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_DIST = 0.1\n",
    "\n",
    "x = np.linspace(0, 3, 300)\n",
    "y = np.exp(- (x-MIN_DIST) * ( (x - MIN_DIST) >=0 ) )\n",
    "\n",
    "dist_low_dim = lambda x, a, b: 1 / (1 + a*x**(2*b))\n",
    "\n",
    "p , _ = optimize.curve_fit(dist_low_dim, x, y)\n",
    "\n",
    "a = p[0]\n",
    "b = p[1] \n",
    "print(\"Hyperparameters a = \" + str(a) + \" and b = \" + str(b))\n",
    "\n",
    "x_p = np.arange(0,3,0.01)\n",
    "y_p = np.exp(- (x_p-MIN_DIST) * ( (x_p - MIN_DIST) >=0 ) )\n",
    "y_p2 = 1 / (1 + a*x_p**(2*b))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x,y, label='Target')\n",
    "plt.plot(x_p,y_p2, label='Fitted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from network_sig import network\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = network(channels=[X_train.shape[1],500,300,200,100,100,100,2]).to(device)\n",
    "\n",
    "\n",
    "criterion_mse = torch.nn.MSELoss()\n",
    "\n",
    "lr = 0.001\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.999))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = []\n",
    "X_train32 = X_train.astype(np.float32)\n",
    "\n",
    "print('Conversion Done')\n",
    "X_torch = torch.as_tensor(X_train32, dtype=torch.float32).to(device)\n",
    "Y_umap = torch.as_tensor(y_umap, dtype=torch.float32).to(device)\n",
    "\n",
    "X_torch_test = torch.as_tensor(X_test, dtype=torch.float32).to(device)\n",
    "print('Tensor Build Done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(n):\n",
    "        if i%10000 == 0:\n",
    "            print('completed ', i, ' of ', n)\n",
    "            \n",
    "        x_st = X_torch[i:i+1,:]\n",
    "        #print(x_st.size())\n",
    "        y_st = model(x_st).cpu().numpy().reshape(-1)\n",
    "        #print(y_st.shape)\n",
    "        Y.append(y_st)\n",
    "\n",
    "Y = np.array(Y)\n",
    "print(Y.shape)\n",
    "\n",
    "\n",
    "plt.figure()#figsize=(20,15))\n",
    "plt.scatter(Y[:,0], Y[:,1], c = y_train.astype(int), cmap = 'Spectral', s = 20)\n",
    "plt.title(\"Random Init\")\n",
    "plt.xlabel(\"Axis-1\") #, fontsize = 20); \n",
    "plt.ylabel(\"Axis-2\") #, fontsize = 20)\n",
    "cbar = plt.colorbar(boundaries=np.arange(11)-0.5)\n",
    "cbar.set_ticks(np.arange(10))\n",
    "cbar.set_ticklabels(classes)\n",
    "plt.show()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion_pos_old(x,y,a,b):\n",
    "    factor = 1 + a * torch.sum((x-y)**2, dim = 0) ** b\n",
    "    y = torch.log(factor)\n",
    "    \n",
    "    return y\n",
    "\n",
    "def criterion_neg_old(x,y,a,b):\n",
    "    factor = a * torch.sum((x-y)**2) ** b\n",
    "    y = - torch.log(0.0001+factor) + torch.log(1 + factor)\n",
    "    \n",
    "    return y\n",
    "\n",
    "def phi(x,y,a,b):\n",
    "    factor = 1 + a * torch.sum((x-y)**2+10**-8, dim=1) ** b\n",
    "    y = 1/factor\n",
    "    \n",
    "    #for i in range(y.size()[0]):\n",
    "    #    if np.isnan(y[i].cpu().detach().item()):\n",
    "    #        print('Isnan in Pos Crit:', i, x[i], y[i])\n",
    "    \n",
    "    return y\n",
    "\n",
    "def criterion_pos(x,y,p,a,b):\n",
    "    prob = phi(x,y,a,b)\n",
    "    y = -torch.log(prob)*p\n",
    "    #for i in range(y.size()[0]):\n",
    "    #    if np.isnan(y[i].cpu().detach().item()):\n",
    "    #        print('Isnan in Pos Crit:', i)\n",
    "    \n",
    "    return torch.sum(y)\n",
    "\n",
    "def criterion_neg(x,y,p,a,b):\n",
    "    prob = phi(x,y,a,b)\n",
    "    y = -torch.log(1-prob+0.000001)*(1-p)\n",
    "    #for i in range(y.size()[0]):\n",
    "    #    if np.isnan(y[i].cpu().detach().item()):\n",
    "    #        print('Isnan in Neg Crit:', i)\n",
    "    \n",
    "    return torch.sum(y)\n",
    "    \n",
    "\n",
    "Y = model(X_torch[0:10,:])\n",
    "Z = criterion_pos(Y[0:4,:],Y[4:8,:],1.0,1.0,1.0)\n",
    "print(Y.size(), Z.size(), Z.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 40\n",
    "\n",
    "print(n)\n",
    "\n",
    "batch_size = 60\n",
    "it_per_epoch = int(n/batch_size)\n",
    "print('Iteration Per Epoch:', it_per_epoch)\n",
    "\n",
    "CE_array = []\n",
    "results = []\n",
    "print(\"Running Gradient Descent: \\n\")\n",
    "\n",
    "Nan_info = False\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    for idx in range(n): #:\n",
    "        choices_0 = np.random.choice(n, batch_size)\n",
    "        k_ch = np.random.randint(low = 0, high = n_neighbors, size=batch_size)\n",
    "        choices_1 = sort_idx[choices_0,k_ch]\n",
    "        \n",
    "        #print(choices_0.shape,choices_1.shape)\n",
    "        \n",
    "        Prob_sample = torch.as_tensor(P[choices_0,choices_1].reshape(-1), dtype=torch.float32).to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss = 0\n",
    "        \n",
    "        Y0 = model(X_torch[choices_0,:])\n",
    "        Y1 = model(X_torch[choices_1,:])\n",
    "        \n",
    "        cr = criterion_pos(Y0, Y1, Prob_sample, a, b)\n",
    "        loss = loss + cr\n",
    "        #print(cr)\n",
    "        \n",
    "        \n",
    "        if np.isnan(cr.detach().cpu().item()):\n",
    "            Nan_info = True\n",
    "            print(epoch,idx,cr)\n",
    "            break\n",
    "        \n",
    "        CE_array.append(cr.cpu().detach().item())\n",
    "    \n",
    "        \n",
    "        for j in range(5):\n",
    "            k_ch = np.random.randint(low = 0, high = n, size=batch_size)\n",
    "            Y1 = model(X_torch[k_ch,:])\n",
    "            Prob_sample = torch.as_tensor(P[choices_0,k_ch].reshape(-1), dtype=torch.float32).to(device)\n",
    "            \n",
    "            cr = criterion_neg(Y0, Y1, Prob_sample, a, b)\n",
    "            loss = loss + cr\n",
    "            if np.isnan(cr.detach().cpu().item()):\n",
    "                Nan_info = True\n",
    "                print('inside loop: ', epoch, idx, j, cr)\n",
    "                break\n",
    "            \n",
    "        if Nan_info == True:\n",
    "            print('EVERYTHING IS NAN')\n",
    "            break\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "                \n",
    "    #LEARNING_RATE = 1.0 - epoch / epochs\n",
    "    if (epoch+1)%1 == 0:\n",
    "        print('Completed ', epoch , ' of ', epochs)\n",
    "        torch.save(model.state_dict(), 'nets_CE/epoch'+str(epoch)+'.pth')\n",
    "        \n",
    "        Y = []\n",
    "        Y_test = []\n",
    "        with torch.no_grad():\n",
    "            for i in range(n):\n",
    "                x_st = X_torch[i:i+1,:]\n",
    "                y_st = model(x_st).cpu().numpy().reshape(-1)\n",
    "                #print(y_st.shape)\n",
    "                Y.append(y_st)\n",
    "            \n",
    "\n",
    "            \n",
    "            for i in range(X_test.shape[0]):\n",
    "                x_st = X_torch_test[i:i+1,:]\n",
    "                #print(x_st.size())\n",
    "                y_st = model(x_st).cpu().numpy().reshape(-1)\n",
    "                #print(y_st.shape)\n",
    "                Y_test.append(y_st)\n",
    "        \n",
    "        Y_test = np.array(Y_test)\n",
    "        Y = np.array(Y)\n",
    "        \n",
    "        neigh.fit(Y, y_train) \n",
    "        y_nene_out = neigh.predict(Y_test)\n",
    "        \n",
    "        result = 1-np.mean(y_nene_out==y_test)\n",
    "        \n",
    "        results.append(result)\n",
    "        \n",
    "        d = {}\n",
    "        d['Y'] = Y\n",
    "        d['Y_test'] = Y_test\n",
    "        savemat('nets_CE/test_data'+str(epoch)+'.mat', d)\n",
    "        \n",
    "        print('Error :', result)\n",
    "        \n",
    "    if (epoch+1)/5 == 0:\n",
    "        lr = lr/10\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(n):\n",
    "        if i%10000 == 0:\n",
    "            print('completed ', i, ' of ', n)\n",
    "            \n",
    "        x_st = X_torch[i:i+1,:]\n",
    "        #print(x_st.size())\n",
    "        y_st = model(x_st).cpu().numpy().reshape(-1)\n",
    "        #print(y_st.shape)\n",
    "        Y.append(y_st)\n",
    "\n",
    "Y = np.array(Y)\n",
    "print(Y)\n",
    "\n",
    "plt.figure()#figsize=(20,15))\n",
    "plt.scatter(Y[:,0], Y[:,1], c = y_train.astype(int), cmap = 'Spectral', s = 20)\n",
    "plt.title(\"UMAP\")\n",
    "plt.xlabel(\"UMAP 1\") #, fontsize = 20); \n",
    "plt.ylabel(\"UMAP 2\") #, fontsize = 20)\n",
    "cbar = plt.colorbar(boundaries=np.arange(11)-0.5)\n",
    "cbar.set_ticks(np.arange(10))\n",
    "cbar.set_ticklabels(classes)\n",
    "plt.show()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
